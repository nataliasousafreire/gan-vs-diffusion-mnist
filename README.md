# ComparaÃ§Ã£o de Modelos de GeraÃ§Ã£o de Imagens: GAN vs DifusÃ£o (MNIST)

## IntroduÃ§Ã£o
Este projeto tem como objetivo comparar dois dos principais paradigmas de modelos generativos: **Redes AdversÃ¡rias Generativas (GANs)** e **Modelos de DifusÃ£o**. Ambos foram treinados utilizando o dataset **MNIST** (dÃ­gitos manuscritos), avaliados com mÃ©tricas quantitativas (FID e IS) e qualitativas (amostras geradas e evoluÃ§Ã£o visual durante o treinamento).

---

## Metodologia

### 1. Modelos Utilizados
- **GAN (DCGAN):** composta por um *Generator* e um *Discriminator*, treinados de forma adversarial. O objetivo Ã© gerar amostras indistinguÃ­veis das reais.  
- **DifusÃ£o (DDPM simplificado):** modelo baseado em um processo de ruÃ­do progressivo e reversÃ£o, com arquitetura *U-Net* e *timestep* configurÃ¡vel.

### 2. Frameworks e Bibliotecas
Ambos os modelos foram implementados em **PyTorch**, com uso das seguintes bibliotecas:
- `torch`, `torchvision`, `numpy`, `tqdm`, `matplotlib`
- CÃ¡lculo de mÃ©tricas: **FID** e **Inception Score (IS)**
- Ferramentas auxiliares: *callbacks*, *schedulers*, *EMA (Exponential Moving Average)* e *Early Stopping* com **paciÃªncia = 10 Ã©pocas**

### 3. HiperparÃ¢metros principais
| ParÃ¢metro | GAN | DifusÃ£o |
|------------|------|----------|
| Ã‰pocas | 100 | 100 |
| Batch Size | 128 | 128 |
| Learning Rate | 1e-4 | 1e-4 |
| Otimizador | Adam | Adam |
| Grad Clip | â€” | 1.0 |
| EMA Decay | 0.999 | 0.999 |
| Timesteps | â€” | 1000 |
| Early Stop Patience | 10 | 10 |

---

## Estrutura do Projeto
```
â”œâ”€â”€ models.py                # Arquiteturas (GAN e U-Net para DifusÃ£o)
â”œâ”€â”€ utils.py                 # FunÃ§Ãµes auxiliares (gravaÃ§Ã£o, loaders, mÃ©tricas)
â”œâ”€â”€ callbacks.py             # Early Stop e reduÃ§Ã£o automÃ¡tica de LR
â”‚
â”œâ”€â”€ samples/                 # Imagens e GIFs gerados
â”‚   â”œâ”€â”€ gan_progress.gif
â”‚   â””â”€â”€ diffusion_progress.gif
â”‚
â”œâ”€â”€ reports/                 # RelatÃ³rios, mÃ©tricas e resultados quantitativos
â”‚   â”œâ”€â”€ fid_comparison.png
â”‚   â”œâ”€â”€ is_comparison.png
â”‚   â”œâ”€â”€ loss_comparison.png
â”‚   â”œâ”€â”€ gan_training_log.csv
â”‚   â”œâ”€â”€ diffusion_training_log.csv
â”‚
â”œâ”€â”€ train_gan.py             # Script de treinamento da GAN
â”œâ”€â”€ train_diffusion.py       # Script de treinamento do modelo de DifusÃ£o
â”œâ”€â”€ infer.py                 # GeraÃ§Ã£o de amostras lado a lado (GAN vs DifusÃ£o)
â””â”€â”€ README.md                # DocumentaÃ§Ã£o 
            
```

 **ObservaÃ§Ã£o importante sobre os modelos treinados:**  
A pasta `checkpoints/`, que contÃ©m os **pesos finais das redes (modelos treinados)**, nÃ£o estÃ¡ incluÃ­da no repositÃ³rio por motivos de tamanho(boas prÃ¡ticas de versionamento desaconselham armazenar arquivos grandes diretamente no Git).
Para executar o script `infer.py` (geraÃ§Ã£o de amostras comparativas), Ã© necessÃ¡rio baixar os modelos prÃ©-treinados e colocÃ¡-los manualmente dentro da pasta `checkpoints/`.

**Download dos modelos:**  
[Acesse aqui o diretÃ³rio no Google Drive](https://drive.google.com/drive/folders/1tXcDfEV6eiGvZHYlHOFJWZ1X0UADNWia?usp=sharing)  
ApÃ³s o download, extraia os arquivos e coloque-os na pasta local:
```
/checkpoints/
â”œâ”€â”€ best_GAN_G.pt
â”œâ”€â”€ best_GAN_D.pt
â””â”€â”€ best_DIFF.pt
 ```
Somente apÃ³s isso, rode o comando:
```bash
python infer.py
```

---

## ExecuÃ§Ã£o

### 1. Treinamento
```bash
# Treinar a GAN
python train_gan.py --epochs 100 --batch-size 128 --ema --early-stop --patience 10

# Treinar o modelo de DifusÃ£o
python train_diffusion.py --epochs 100 --batch-size 128 --ema --early-stop --timesteps 1000 --patience 10
```

### 2. InferÃªncia
GeraÃ§Ã£o de imagens lado a lado com ambos os modelos:
```bash
python infer.py 
```

### 3. Resultados
Os resultados quantitativos e qualitativos sÃ£o salvos automaticamente em:
```
/reports/  â†’ mÃ©tricas e grÃ¡ficos
/samples/ â†’ amostras e GIFs
```

---

## Resultados e AnÃ¡lises

### 1. EvoluÃ§Ã£o Visual

#### DifusÃ£o
<p>
  <img src="./samples/diffusion_progress.gif" alt="Diffusion Progress" width="224" />
</p>

#### GAN
<p>
  <img src="./samples/gan_progress.gif" alt="GAN Progress" width="224" />
</p>



### 2. GrÃ¡ficos de Desempenho
- **FID (FrÃ©chet Inception Distance)** â€” quanto menor, melhor qualidade:
  
  ![FID Comparison](reports/fid_comparison.png)
  

- **Inception Score (IS)** â€” quanto maior, maior diversidade:
  
  ![IS Comparison](reports/is_comparison.png)
  

- **Loss / FID Over Time:**
  
  ![Loss Comparison](reports/loss_comparison.png)
  

### 3. MÃ©tricas Finais
| Modelo | FID â†“ | IS â†‘ (mÃ©dia) | IS Std |
|---------|--------|--------------|---------|
| Difusao | **78.4** | 1.62 | 0.08 |
| GAN | **46.9** | 1.91 | 0.05 |

---

## DiscussÃ£o dos Resultados

- **GAN:** Apresentou convergÃªncia rÃ¡pida nas primeiras Ã©pocas, caracterÃ­stica esperada em modelos adversariais, pois o gerador tende a aprender padrÃµes bÃ¡sicos de estrutura visual de forma inicial. No entanto, observou-se um comportamento oscilatÃ³rio apÃ³s certo ponto, possivelmente devido ao desequilÃ­brio momentÃ¢neo entre as redesm quando o discriminador se torna excessivamente preciso, o gerador perde gradientes Ãºteis e a estabilidade do processo Ã© afetada. Esse fenÃ´meno, comum em GANs, reflete a sensibilidade da tÃ©cnica Ã  escolha de hiperparÃ¢metros e Ã  dinÃ¢mica competitiva entre as duas redes.
- **DifusÃ£o:** Exibiu um comportamento de convergÃªncia mais estÃ¡vel e progressivo. Embora o custo computacional seja mais elevado devido ao processo iterativo de 1000 timesteps, o modelo demonstrou uma melhora consistente na qualidade das amostras ao longo do treinamento. A difusÃ£o tende a produzir imagens mais suaves e coerentes, uma vez que o processo de reversÃ£o do ruÃ­do (denoising) Ã© aprendido de forma gradual e controlada, o que reduz a ocorrÃªncia de artefatos visuais.
- **EMA:** : O uso da mÃ©dia exponencial mÃ³vel (EMA) mostrou-se fundamental para suavizar o aprendizado e reduzir a variÃ¢ncia entre iteraÃ§Ãµes, especialmente na fase final de convergÃªncia. JÃ¡ o early stopping com paciÃªncia de 10 Ã©pocas impediu o sobreajuste em ambas as abordagens, interrompendo o treinamento quando nÃ£o havia melhoria significativa no FID. Essa combinaÃ§Ã£o contribuiu diretamente para maior estabilidade e consistÃªncia dos resultados.
- **FID vs IS:** O comportamento das mÃ©tricas foi coerente com o observado na literatura. O modelo de difusÃ£o alcanÃ§ou valores de FID substancialmente menores, indicando maior proximidade das amostras geradas em relaÃ§Ã£o Ã  distribuiÃ§Ã£o real dos dados. Por outro lado, a GAN obteve pontuaÃ§Ãµes de Inception Score ligeiramente superiores nas primeiras fases do treinamento, refletindo uma maior diversidade nas imagens geradas â€” embora nem sempre acompanhada de realismo estrutural. Essa relaÃ§Ã£o inversa entre diversidade (IS) e fidelidade (FID) Ã© tÃ­pica quando se comparam modelos adversariais e difusionais.

---

## ConclusÃ£o

- **GAN:** Apresentou rÃ¡pido aprendizado e capacidade de gerar amostras visualmente diversas logo nas primeiras Ã©pocas. Apesar de certa instabilidade inerente ao treinamento adversarial, seu desempenho neste experimento foi superior, alcanÃ§ando resultados mais consistentes nas mÃ©tricas quantitativas e demonstrando boa eficiÃªncia computacional.
- **DifusÃ£o:** manteve comportamento estÃ¡vel e produziu imagens com maior coerÃªncia local, mas com custo computacional elevado e resultados quantitativos inferiores no cenÃ¡rio avaliado.

**ConclusÃ£o geral:** : neste experimento, a GAN superou o modelo de DifusÃ£o, apresentando melhor desempenho geral mesmo com maior instabilidade durante o treino.

ğŸ“¦ **RepositÃ³rio estruturado para fÃ¡cil reproduÃ§Ã£o:**
```bash
git clone https://github.com/usuario/Comparacao-GAN-vs-Difusao.git
cd Comparacao-GAN-vs-Difusao
pip install -r requirements.txt
```
