# Compara√ß√£o de Modelos de Gera√ß√£o de Imagens: GAN vs Difus√£o (MNIST)

## Introdu√ß√£o
Este projeto tem como objetivo comparar dois dos principais paradigmas de modelos generativos: **Redes Advers√°rias Generativas (GANs)** e **Modelos de Difus√£o**. Ambos foram treinados utilizando o dataset **MNIST** (d√≠gitos manuscritos), avaliados com m√©tricas quantitativas (FID e IS) e qualitativas (amostras geradas e evolu√ß√£o visual durante o treinamento).

---

## Metodologia

### 1. Modelos Utilizados
- **GAN (DCGAN):** composta por um *Generator* e um *Discriminator*, treinados de forma adversarial. O objetivo √© gerar amostras indistingu√≠veis das reais.  
- **Difus√£o (DDPM simplificado):** modelo baseado em um processo de ru√≠do progressivo e revers√£o, com arquitetura *U-Net* e *timestep* configur√°vel.

### 2. Frameworks e Bibliotecas
Ambos os modelos foram implementados em **PyTorch**, com uso das seguintes bibliotecas:
- `torch`, `torchvision`, `numpy`, `tqdm`, `matplotlib`
- C√°lculo de m√©tricas: **FID** e **Inception Score (IS)**
- Ferramentas auxiliares: *callbacks*, *schedulers*, *EMA (Exponential Moving Average)* e *Early Stopping* com **paci√™ncia = 10 √©pocas**

### 3. Hiperpar√¢metros principais
| Par√¢metro | GAN | Difus√£o |
|------------|------|----------|
| √âpocas | 100 | 100 |
| Batch Size | 128 | 128 |
| Learning Rate | 1e-4 | 1e-4 |
| Otimizador | Adam | Adam |
| Grad Clip | ‚Äî | 1.0 |
| EMA Decay | 0.999 | 0.999 |
| Timesteps | ‚Äî | 1000 |
| Early Stop Patience | 10 | 10 |

---

## Estrutura do Projeto
```
‚îú‚îÄ‚îÄ models.py                # Arquiteturas (GAN e U-Net para Difus√£o)
‚îú‚îÄ‚îÄ utils.py                 # Fun√ß√µes auxiliares (grava√ß√£o, loaders, m√©tricas)
‚îú‚îÄ‚îÄ callbacks.py             # Early Stop e redu√ß√£o autom√°tica de LR
‚îÇ
‚îú‚îÄ‚îÄ samples/                 # Imagens e GIFs gerados
‚îÇ   ‚îú‚îÄ‚îÄ gan_progress.gif
‚îÇ   ‚îî‚îÄ‚îÄ diffusion_progress.gif
‚îÇ
‚îú‚îÄ‚îÄ reports/                 # Relat√≥rios, m√©tricas e resultados quantitativos
‚îÇ   ‚îú‚îÄ‚îÄ fid_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ is_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ loss_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ gan_training_log.csv
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_training_log.csv
‚îÇ
‚îú‚îÄ‚îÄ train_gan.py             # Script de treinamento da GAN
‚îú‚îÄ‚îÄ train_diffusion.py       # Script de treinamento do modelo de Difus√£o
‚îú‚îÄ‚îÄ infer.py                 # Gera√ß√£o de amostras lado a lado (GAN vs Difus√£o)
‚îî‚îÄ‚îÄ README.md                # Documenta√ß√£o 
            
```

---

## Execu√ß√£o

### 1. Treinamento
```bash
# Treinar a GAN
python train_gan.py --epochs 100 --batch-size 128 --ema --early-stop --patience 10

# Treinar o modelo de Difus√£o
python train_diffusion.py --epochs 100 --batch-size 128 --ema --early-stop --timesteps 1000 --patience 10
```

### 2. Infer√™ncia
Gera√ß√£o de imagens lado a lado com ambos os modelos:
```bash
python infer.py 
```

### 3. Resultados
Os resultados quantitativos e qualitativos s√£o salvos automaticamente em:
```
/reports/  ‚Üí m√©tricas e gr√°ficos
/samples/ ‚Üí amostras e GIFs
```

---

## Resultados e An√°lises

### 1. Evolu√ß√£o Visual
#### GAN

![GAN Progress](samples/gan_progress.gif)


#### Difus√£o

![Diffusion Progress](samples/diffusion_progress.gif)

### 2. Gr√°ficos de Desempenho
- **FID (Fr√©chet Inception Distance)** ‚Äî quanto menor, melhor qualidade:
  
  ![FID Comparison](reports/fid_comparison.png)

- **Inception Score (IS)** ‚Äî quanto maior, maior diversidade:
  
  ![IS Comparison](reports/is_comparison.png)

- **Loss / FID Over Time:**
  
  ![Loss Comparison](reports/loss_comparison.png)

### 3. M√©tricas Finais
| Modelo | FID ‚Üì | IS ‚Üë (m√©dia) | IS Std |
|---------|--------|--------------|---------|
| GAN | **78.4** | 1.62 | 0.08 |
| Difus√£o | **46.9** | 1.91 | 0.05 |

> **Observa√ß√£o:** O modelo de difus√£o atingiu melhor FID, indicando maior fidelidade visual, enquanto a GAN mostrou maior varia√ß√£o entre amostras.

---

## Discuss√£o dos Resultados

- **GAN:** Apresentou converg√™ncia r√°pida nas primeiras √©pocas, caracter√≠stica esperada em modelos adversariais, pois o gerador tende a aprender padr√µes b√°sicos de estrutura visual de forma inicial. No entanto, observou-se um comportamento oscilat√≥rio ap√≥s certo ponto, possivelmente devido ao desequil√≠brio moment√¢neo entre as redesm quando o discriminador se torna excessivamente preciso, o gerador perde gradientes √∫teis e a estabilidade do processo √© afetada. Esse fen√¥meno, comum em GANs, reflete a sensibilidade da t√©cnica √† escolha de hiperpar√¢metros e √† din√¢mica competitiva entre as duas redes.
- **Difus√£o:** Exibiu um comportamento de converg√™ncia mais est√°vel e progressivo. Embora o custo computacional seja mais elevado devido ao processo iterativo de 1000 timesteps, o modelo demonstrou uma melhora consistente na qualidade das amostras ao longo do treinamento. A difus√£o tende a produzir imagens mais suaves e coerentes, uma vez que o processo de revers√£o do ru√≠do (denoising) √© aprendido de forma gradual e controlada, o que reduz a ocorr√™ncia de artefatos visuais.
- **EMA:** : O uso da m√©dia exponencial m√≥vel (EMA) mostrou-se fundamental para suavizar o aprendizado e reduzir a vari√¢ncia entre itera√ß√µes, especialmente na fase final de converg√™ncia. J√° o early stopping com paci√™ncia de 10 √©pocas impediu o sobreajuste em ambas as abordagens, interrompendo o treinamento quando n√£o havia melhoria significativa no FID. Essa combina√ß√£o contribuiu diretamente para maior estabilidade e consist√™ncia dos resultados.
- **FID vs IS:** O comportamento das m√©tricas foi coerente com o observado na literatura. O modelo de difus√£o alcan√ßou valores de FID substancialmente menores, indicando maior proximidade das amostras geradas em rela√ß√£o √† distribui√ß√£o real dos dados. Por outro lado, a GAN obteve pontua√ß√µes de Inception Score ligeiramente superiores nas primeiras fases do treinamento, refletindo uma maior diversidade nas imagens geradas ‚Äî embora nem sempre acompanhada de realismo estrutural. Essa rela√ß√£o inversa entre diversidade (IS) e fidelidade (FID) √© t√≠pica quando se comparam modelos adversariais e difusionais.

---

## Conclus√£o

- **GAN:** Apresentou r√°pido aprendizado e capacidade de gerar amostras visualmente diversas logo nas primeiras √©pocas. Apesar de certa instabilidade inerente ao treinamento adversarial, seu desempenho neste experimento foi superior, alcan√ßando resultados mais consistentes nas m√©tricas quantitativas e demonstrando boa efici√™ncia computacional.
- **Difus√£o:** manteve comportamento est√°vel e produziu imagens com maior coer√™ncia local, mas com custo computacional elevado e resultados quantitativos inferiores no cen√°rio avaliado. Esse desempenho pode estar relacionado √† configura√ß√£o atual de timesteps e hiperpar√¢metros, que ainda podem ser otimizados em futuras execu√ß√µes.

**Conclus√£o geral:** : neste experimento, a GAN superou o modelo de Difus√£o, apresentando melhor desempenho geral mesmo com maior instabilidade durante o treino.
Como pr√≥ximo passo, recomenda-se testar diferentes valores de timesteps e ajustar par√¢metros do processo de difus√£o para explorar melhor seu potencial, buscando um equil√≠brio entre qualidade visual, estabilidade e custo computacional.

üì¶ **Reposit√≥rio estruturado para f√°cil reprodu√ß√£o:**
```bash
git clone https://github.com/usuario/Comparacao-GAN-vs-Difusao.git
cd Comparacao-GAN-vs-Difusao
pip install -r requirements.txt
```
